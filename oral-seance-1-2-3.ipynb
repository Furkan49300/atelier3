{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf05d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n",
       "defined class TitanicGroup\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//seance 1 etape 3\n",
    "case class TitanicGroup(\n",
    "  rownames: Int,\n",
    "  pClass: String,\n",
    "  sex: String,\n",
    "  age: String,\n",
    "  survived: String,\n",
    "  freq: Int\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17e8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----+--------+----+\n",
      "|rownames|pClass|   sex|  age|survived|freq|\n",
      "+--------+------+------+-----+--------+----+\n",
      "|       1|   1st|  Male|Child|      No|   0|\n",
      "|       2|   2nd|  Male|Child|      No|   0|\n",
      "|       3|   3rd|  Male|Child|      No|  35|\n",
      "|       4|  Crew|  Male|Child|      No|   0|\n",
      "|       5|   1st|Female|Child|      No|   0|\n",
      "|       6|   2nd|Female|Child|      No|   0|\n",
      "|       7|   3rd|Female|Child|      No|  17|\n",
      "|       8|  Crew|Female|Child|      No|   0|\n",
      "|       9|   1st|  Male|Adult|      No| 118|\n",
      "|      10|   2nd|  Male|Adult|      No| 154|\n",
      "|      11|   3rd|  Male|Adult|      No| 387|\n",
      "|      12|  Crew|  Male|Adult|      No| 670|\n",
      "|      13|   1st|Female|Adult|      No|   4|\n",
      "|      14|   2nd|Female|Adult|      No|  13|\n",
      "|      15|   3rd|Female|Adult|      No|  89|\n",
      "|      16|  Crew|Female|Adult|      No|   3|\n",
      "|      17|   1st|  Male|Child|     Yes|   5|\n",
      "|      18|   2nd|  Male|Child|     Yes|  11|\n",
      "|      19|   3rd|  Male|Child|     Yes|  13|\n",
      "|      20|  Crew|  Male|Child|     Yes|   0|\n",
      "+--------+------+------+-----+--------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- rownames: integer (nullable = false)\n",
      " |-- pClass: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- survived: string (nullable = true)\n",
      " |-- freq: integer (nullable = false)\n",
      "\n",
      "Nombre total de lignes : 32\n",
      "+-------+----------------+------+------+-----+--------+------------------+\n",
      "|summary|        rownames|pClass|   sex|  age|survived|              freq|\n",
      "+-------+----------------+------+------+-----+--------+------------------+\n",
      "|  count|              32|    32|    32|   32|      32|                32|\n",
      "|   mean|            16.5|  NULL|  NULL| NULL|    NULL|          68.78125|\n",
      "| stddev|9.38083151964686|  NULL|  NULL| NULL|    NULL|135.99590467624265|\n",
      "|    min|               1|   1st|Female|Adult|      No|                 0|\n",
      "|    25%|               8|  NULL|  NULL| NULL|    NULL|                 0|\n",
      "|    50%|              16|  NULL|  NULL| NULL|    NULL|                13|\n",
      "|    75%|              24|  NULL|  NULL| NULL|    NULL|                76|\n",
      "|    max|              32|  Crew|  Male|Child|     Yes|               670|\n",
      "+-------+----------------+------+------+-----+--------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rawRdd = Titanic.csv MapPartitionsRDD[1] at textFile at <console>:28\n",
       "header = rownames,Class,Sex,Age,Survived,Freq\n",
       "dataRdd = MapPartitionsRDD[2] at filter at <console>:31\n",
       "titanicRdd = MapPartitionsRDD[4] at map at <console>:33\n",
       "titanicDf = [rownames: int, pClass: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[rownames: int, pClass: string ... 4 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//seance 2 etape 1\n",
    "\n",
    "val rawRdd = sc.textFile(\"Titanic.csv\")\n",
    "\n",
    "val header = rawRdd.first()\n",
    "val dataRdd = rawRdd.filter(_ != header)\n",
    "\n",
    "val titanicRdd = dataRdd.map(_.split(\",\")).map(cols => TitanicGroup(\n",
    "  cols(0).toInt,\n",
    "  cols(1),\n",
    "  cols(2),\n",
    "  cols(3),\n",
    "  cols(4),\n",
    "  cols(5).toInt\n",
    "))\n",
    "\n",
    "val titanicDf = titanicRdd.toDF()\n",
    "\n",
    "titanicDf.show()        \n",
    "titanicDf.printSchema()\n",
    "println(s\"Nombre total de lignes : ${titanicDf.count()}\")\n",
    "titanicDf.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e081a9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfPClass = [pClass: string, id_pclass: bigint]\n",
       "dfSex = [sex: string, id_sex: bigint]\n",
       "dfAge = [age: string, id_age: bigint]\n",
       "dfSurvived = [survived: string, id_survived: bigint]\n",
       "titanicWithPClass = [rownames: int, sex: string ... 4 more fields]\n",
       "titanicWithSex = [rownames: int, age: string ... 4 more fields]\n",
       "titanicWithAge = [rownames: int, survived: string ... 4 more fields]\n",
       "titanicFinalDf = [rownames: int, freq: int ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[rownames: int, freq: int ... 4 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//seance 2 etape 2\n",
    "import org.apache.spark.sql.functions.monotonically_increasing_id\n",
    "\n",
    "\n",
    "val dfPClass = titanicDf\n",
    "  .select(\"pClass\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_pclass\", monotonically_increasing_id)\n",
    "\n",
    "\n",
    "val dfSex = titanicDf\n",
    "  .select(\"sex\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_sex\", monotonically_increasing_id)\n",
    "\n",
    "val dfAge = titanicDf\n",
    "  .select(\"age\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_age\", monotonically_increasing_id)\n",
    "\n",
    "val dfSurvived = titanicDf\n",
    "  .select(\"survived\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_survived\", monotonically_increasing_id)\n",
    "\n",
    "val titanicWithPClass = titanicDf\n",
    "  .join(dfPClass, Seq(\"pClass\"), \"left\")\n",
    "  .drop(\"pClass\")\n",
    "\n",
    "\n",
    "val titanicWithSex = titanicWithPClass\n",
    "  .join(dfSex, Seq(\"sex\"), \"left\")\n",
    "  .drop(\"sex\")\n",
    "\n",
    "\n",
    "val titanicWithAge = titanicWithSex\n",
    "  .join(dfAge, Seq(\"age\"), \"left\")\n",
    "  .drop(\"age\")\n",
    "\n",
    "\n",
    "val titanicFinalDf = titanicWithAge\n",
    "  .join(dfSurvived, Seq(\"survived\"), \"left\")\n",
    "  .drop(\"survived\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cec2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+\n",
      "|  sexe|survie|nb_passagers|\n",
      "+------+------+------------+\n",
      "|  Male|    No|           8|\n",
      "|  Male|   Yes|           8|\n",
      "|Female|    No|           8|\n",
      "|Female|   Yes|           8|\n",
      "+------+------+------------+\n",
      "\n",
      "+------+-----------+---+\n",
      "|classe|tranche_age| nb|\n",
      "+------+-----------+---+\n",
      "|   3rd|      Child|  4|\n",
      "|   2nd|      Adult|  4|\n",
      "|   2nd|      Child|  4|\n",
      "|   3rd|      Adult|  4|\n",
      "|  Crew|      Adult|  4|\n",
      "|  Crew|      Child|  4|\n",
      "|   1st|      Adult|  4|\n",
      "|   1st|      Child|  4|\n",
      "+------+-----------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException = null\n",
       "hc = org.apache.spark.sql.hive.HiveContext@74efcc29\n",
       "test = [sexe: string, survie: string ... 1 more field]\n",
       "zeub = [classe: string, tranche_age: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: one deprecation (since 2.0.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[classe: string, tranche_age: string ... 1 more field]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//seance 2 etape 3\n",
    "import org.apache.spark.sql.hive.HiveContext\n",
    "\n",
    "val hc = new HiveContext(sc)\n",
    "dfPClass.write.mode(\"overwrite\").saveAsTable(\"dim_pclass\")\n",
    "dfSex.write.mode(\"overwrite\").saveAsTable(\"dim_sex\")\n",
    "dfAge.write.mode(\"overwrite\").saveAsTable(\"dim_age\")\n",
    "dfSurvived.write.mode(\"overwrite\").saveAsTable(\"dim_survived\")\n",
    "titanicFinalDf.write.mode(\"overwrite\").saveAsTable(\"fact_titanic\")\n",
    "\n",
    "val test = hc.sql(\"\"\"\n",
    "  SELECT s.sex AS sexe, surv.survived AS survie, COUNT(*) AS nb_passagers\n",
    "  FROM fact_titanic f\n",
    "  JOIN dim_sex s ON f.id_sex = s.id_sex\n",
    "  JOIN dim_survived surv ON f.id_survived = surv.id_survived\n",
    "  GROUP BY s.sex, surv.survived\n",
    "\"\"\")\n",
    "test.show()\n",
    "\n",
    "\n",
    "val zeub = hc.sql(\"\"\"\n",
    "  SELECT c.pClass AS classe, a.age AS tranche_age, COUNT(*) AS nb\n",
    "  FROM fact_titanic f\n",
    "  JOIN dim_pclass c ON f.id_pclass = c.id_pclass\n",
    "  JOIN dim_age a ON f.id_age = a.id_age\n",
    "  GROUP BY c.pClass, a.age\n",
    "\"\"\")\n",
    "zeub.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140c705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+\n",
      "|pClass|   sex|total_passengers|\n",
      "+------+------+----------------+\n",
      "|   2nd|  Male|             179|\n",
      "|   2nd|Female|             106|\n",
      "|  Crew|Female|              23|\n",
      "|  Crew|  Male|             862|\n",
      "|   3rd|Female|             196|\n",
      "|   1st|  Male|             180|\n",
      "|   1st|Female|             145|\n",
      "|   3rd|  Male|             510|\n",
      "+------+------+----------------+\n",
      "\n",
      "+-----+---------+\n",
      "|  age|survivors|\n",
      "+-----+---------+\n",
      "|Adult|      654|\n",
      "|Child|       57|\n",
      "+-----+---------+\n",
      "\n",
      "+--------+----------------+\n",
      "|survived|total_passengers|\n",
      "+--------+----------------+\n",
      "|     Yes|             711|\n",
      "|      No|            1490|\n",
      "+--------+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pClass: string, sex: string ... 2 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "hc = org.apache.spark.sql.hive.HiveContext@20cb36ff\n",
       "survieParClasse = [pClass: string, survival_rate: decimal(27,2)]\n",
       "survieParSexe = [sex: string, survival_rate: decimal(27,2)]\n",
       "tauxMortaliteCroise = [pClass: string, sex: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: one deprecation (since 2.0.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.sql.hive.HiveContext\n",
    "\n",
    "val hc = new HiveContext(sc)\n",
    "\n",
    "titanicDf.write.mode(\"overwrite\").saveAsTable(\"titanic\")\n",
    "\n",
    "val survieParClasse = hc.sql(\"\"\"\n",
    "  SELECT pClass,\n",
    "         ROUND(SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS survival_rate\n",
    "  FROM titanic\n",
    "  GROUP BY pClass\n",
    "\"\"\")\n",
    "\n",
    "val survieParSexe = hc.sql(\"\"\"\n",
    "  SELECT sex,\n",
    "         ROUND(SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS survival_rate\n",
    "  FROM titanic\n",
    "  GROUP BY sex\n",
    "\"\"\")\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT pClass, sex, SUM(freq) AS total_passengers\n",
    "  FROM titanic\n",
    "  GROUP BY pClass, sex\n",
    "\"\"\").show()\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT age, SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) AS survivors\n",
    "  FROM titanic\n",
    "  GROUP BY age\n",
    "\"\"\").show()\n",
    "\n",
    "val tauxMortaliteCroise = hc.sql(\"\"\"\n",
    "  SELECT pClass, sex, age,\n",
    "         ROUND(SUM(CASE WHEN survived = 'No' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS death_rate\n",
    "  FROM titanic\n",
    "  GROUP BY pClass, sex, age\n",
    "\"\"\")\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT survived, SUM(freq) AS total_passengers\n",
    "  FROM titanic\n",
    "  GROUP BY survived\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d446acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "//seance 3 etape 2\n",
    "survieParClasse.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/survival_rate_by_class\")\n",
    "\n",
    "  survieParSexe.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/survival_rate_by_sex\")\n",
    "\n",
    "  tauxMortaliteCroise.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/death_rate_class_sex_age\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
