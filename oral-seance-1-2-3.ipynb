{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class TitanicGroup\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//seance 1 etape 3\n",
    "case class TitanicGroup(\n",
    "  rownames: Int,\n",
    "  pClass: String,\n",
    "  sex: String,\n",
    "  age: String,\n",
    "  survived: String,\n",
    "  freq: Int\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "//seance 2 etape 1\n",
    "\n",
    "val rawRdd = sc.textFile(\"Titanic.csv\")\n",
    "\n",
    "val header = rawRdd.first()\n",
    "val dataRdd = rawRdd.filter(_ != header)\n",
    "\n",
    "val titanicRdd = dataRdd.map(_.split(\",\")).map(cols => TitanicGroup(\n",
    "  cols(0).toInt,\n",
    "  cols(1),\n",
    "  cols(2),\n",
    "  cols(3),\n",
    "  cols(4),\n",
    "  cols(5).toInt\n",
    "))\n",
    "\n",
    "val titanicDf = titanicRdd.toDF()\n",
    "\n",
    "titanicDf.show()        \n",
    "titanicDf.printSchema()\n",
    "println(s\"Nombre total de lignes : ${titanicDf.count()}\")\n",
    "titanicDf.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "//seance 2 etape 2\n",
    "import org.apache.spark.sql.functions.monotonically_increasing_id\n",
    "\n",
    "\n",
    "val dfPClass = titanicDf\n",
    "  .select(\"pClass\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_pclass\", monotonically_increasing_id)\n",
    "\n",
    "\n",
    "val dfSex = titanicDf\n",
    "  .select(\"sex\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_sex\", monotonically_increasing_id)\n",
    "\n",
    "val dfAge = titanicDf\n",
    "  .select(\"age\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_age\", monotonically_increasing_id)\n",
    "\n",
    "val dfSurvived = titanicDf\n",
    "  .select(\"survived\")\n",
    "  .distinct()\n",
    "  .withColumn(\"id_survived\", monotonically_increasing_id)\n",
    "\n",
    "val titanicWithPClass = titanicDf\n",
    "  .join(dfPClass, Seq(\"pClass\"), \"left\")\n",
    "  .drop(\"pClass\")\n",
    "\n",
    "\n",
    "val titanicWithSex = titanicWithPClass\n",
    "  .join(dfSex, Seq(\"sex\"), \"left\")\n",
    "  .drop(\"sex\")\n",
    "\n",
    "\n",
    "val titanicWithAge = titanicWithSex\n",
    "  .join(dfAge, Seq(\"age\"), \"left\")\n",
    "  .drop(\"age\")\n",
    "\n",
    "\n",
    "val titanicFinalDf = titanicWithAge\n",
    "  .join(dfSurvived, Seq(\"survived\"), \"left\")\n",
    "  .drop(\"survived\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "//seance 2 etape 3\n",
    "import org.apache.spark.sql.hive.HiveContext\n",
    "\n",
    "val hc = new HiveContext(sc)\n",
    "dfPClass.write.mode(\"overwrite\").saveAsTable(\"dim_pclass\")\n",
    "dfSex.write.mode(\"overwrite\").saveAsTable(\"dim_sex\")\n",
    "dfAge.write.mode(\"overwrite\").saveAsTable(\"dim_age\")\n",
    "dfSurvived.write.mode(\"overwrite\").saveAsTable(\"dim_survived\")\n",
    "titanicFinalDf.write.mode(\"overwrite\").saveAsTable(\"fact_titanic\")\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT s.label AS sexe, surv.label AS survie, COUNT(*) AS nb_passagers\n",
    "  FROM fact_titanic f\n",
    "  JOIN dim_sex s ON f.id_sex = s.id_sex\n",
    "  JOIN dim_survived surv ON f.id_survived = surv.id_survived\n",
    "  GROUP BY s.label, surv.label\n",
    "\"\"\").show()\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT c.label AS classe, a.label AS tranche_age, COUNT(*) AS nb\n",
    "  FROM fact_titanic f\n",
    "  JOIN dim_pclass c ON f.id_pclass = c.id_pclass\n",
    "  JOIN dim_age a ON f.id_age = a.id_age\n",
    "  GROUP BY c.label, a.label\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+\n",
      "|pClass|   sex|total_passengers|\n",
      "+------+------+----------------+\n",
      "|   2nd|  Male|             179|\n",
      "|   2nd|Female|             106|\n",
      "|  Crew|Female|              23|\n",
      "|  Crew|  Male|             862|\n",
      "|   3rd|Female|             196|\n",
      "|   1st|  Male|             180|\n",
      "|   1st|Female|             145|\n",
      "|   3rd|  Male|             510|\n",
      "+------+------+----------------+\n",
      "\n",
      "+-----+---------+\n",
      "|  age|survivors|\n",
      "+-----+---------+\n",
      "|Adult|      654|\n",
      "|Child|       57|\n",
      "+-----+---------+\n",
      "\n",
      "+--------+----------------+\n",
      "|survived|total_passengers|\n",
      "+--------+----------------+\n",
      "|     Yes|             711|\n",
      "|      No|            1490|\n",
      "+--------+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException = null\n",
       "hc = org.apache.spark.sql.hive.HiveContext@7c1167ac\n",
       "survieParClasse = [pClass: string, survival_rate: decimal(27,2)]\n",
       "survieParSexe = [sex: string, survival_rate: decimal(27,2)]\n",
       "tauxMortaliteCroise = [pClass: string, sex: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: one deprecation (since 2.0.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[pClass: string, sex: string ... 2 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.hive.HiveContext\n",
    "\n",
    "val hc = new HiveContext(sc)\n",
    "\n",
    "titanicDf.write.mode(\"overwrite\").saveAsTable(\"titanic\")\n",
    "\n",
    "val survieParClasse = hc.sql(\"\"\"\n",
    "  SELECT pClass,\n",
    "         ROUND(SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS survival_rate\n",
    "  FROM titanic\n",
    "  GROUP BY pClass\n",
    "\"\"\")\n",
    "\n",
    "val survieParSexe = hc.sql(\"\"\"\n",
    "  SELECT sex,\n",
    "         ROUND(SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS survival_rate\n",
    "  FROM titanic\n",
    "  GROUP BY sex\n",
    "\"\"\")\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT pClass, sex, SUM(freq) AS total_passengers\n",
    "  FROM titanic\n",
    "  GROUP BY pClass, sex\n",
    "\"\"\").show()\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT age, SUM(CASE WHEN survived = 'Yes' THEN freq ELSE 0 END) AS survivors\n",
    "  FROM titanic\n",
    "  GROUP BY age\n",
    "\"\"\").show()\n",
    "\n",
    "val tauxMortaliteCroise = hc.sql(\"\"\"\n",
    "  SELECT pClass, sex, age,\n",
    "         ROUND(SUM(CASE WHEN survived = 'No' THEN freq ELSE 0 END) * 100.0 / SUM(freq), 2) AS death_rate\n",
    "  FROM titanic\n",
    "  GROUP BY pClass, sex, age\n",
    "\"\"\")\n",
    "\n",
    "hc.sql(\"\"\"\n",
    "  SELECT survived, SUM(freq) AS total_passengers\n",
    "  FROM titanic\n",
    "  GROUP BY survived\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d446acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "//seance 3 etape 2\n",
    "survieParClasse.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/survival_rate_by_class\")\n",
    "\n",
    "  survieParSexe.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/survival_rate_by_sex\")\n",
    "\n",
    "  tauxMortaliteCroise.coalesce(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .save(\"out/death_rate_class_sex_age\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
